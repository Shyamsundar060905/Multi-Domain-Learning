{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7b2ef8-33ab-479a-8217-d06f2fa880b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "#UCMerced\n",
    "#Elastic WEight consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db0e89d5-d84d-43f4-8a45-f2d867341538",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualAdapter(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=32):\n",
    "        super().__init__()\n",
    "\n",
    "        bottleneck = in_channels // reduction   # reduced channels\n",
    "\n",
    "        self.adapter = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, bottleneck, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(bottleneck),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(bottleneck, in_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(in_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.adapter(x)\n",
    "\n",
    "\n",
    "class AdapterBlock(nn.Module):\n",
    "    def __init__(self, block, channels):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "        self.bn = nn.BatchNorm2d(channels)\n",
    "        self.adapter = ResidualAdapter(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        block_out = self.block(x)\n",
    "        normed = self.bn(block_out)\n",
    "        return block_out + self.adapter(normed)\n",
    "    \n",
    "class ResNetWithAdapters(nn.Module):\n",
    "    def __init__(self, base, domain_list, domain_num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Shared stem\n",
    "        self.stem = nn.Sequential(\n",
    "            base.conv1,\n",
    "            base.bn1,\n",
    "            base.relu,\n",
    "            base.maxpool\n",
    "        )\n",
    "        self.base_layers = nn.ModuleDict({\n",
    "            'layer1': base.layer1,\n",
    "            'layer2': base.layer2,\n",
    "            'layer3': base.layer3,\n",
    "            'layer4': base.layer4\n",
    "        })\n",
    "        \n",
    "                # Shared layers (no adapters)\n",
    "        self.layer1 = base.layer1\n",
    "        self.layer2 = base.layer2\n",
    "\n",
    "        # Domain-specific adapters only for last 2 layers\n",
    "        self.adapters = nn.ModuleDict({\n",
    "            domain: nn.ModuleDict({\n",
    "                'layer3': self._wrap_with_adapters(base.layer3, 1024),\n",
    "                'layer4': self._wrap_with_adapters(base.layer4, 2048)\n",
    "            })\n",
    "            for domain in domain_list\n",
    "        })\n",
    "\n",
    "        # Classifiers per domain\n",
    "        self.classifiers = nn.ModuleDict({\n",
    "            domain: nn.Linear(2048, domain_num_classes[domain])\n",
    "            for domain in domain_list\n",
    "        })\n",
    "\n",
    "        self.avgpool = base.avgpool\n",
    "\n",
    "    def _wrap_with_adapters(self, layer, channels):\n",
    "        # Wrap each block with AdapterBlock\n",
    "        return nn.Sequential(\n",
    "            *[AdapterBlock(block, channels) for block in layer]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, domain):\n",
    "        x = self.stem(x)\n",
    "\n",
    "        # Shared\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        # Domain-specific adapters\n",
    "        x = self.adapters[domain]['layer3'](x)\n",
    "        x = self.adapters[domain]['layer4'](x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifiers[domain](x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a4cc688-102c-4f2a-8f7f-ac2dca8a09ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2bf6f01-2222-4ed8-8ac9-2bd192dc0150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class HFDatasetWrapper(Dataset):\n",
    "    def __init__(self, dataset, transform=None, label_key='label', label_to_idx=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.label_key = label_key\n",
    "        self.label_to_idx = label_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        image = np.array(item['image'])\n",
    "        image = Image.fromarray(image)\n",
    "    \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "    \n",
    "        label = item[self.label_key]\n",
    "    \n",
    "        if self.label_to_idx is not None:\n",
    "            if isinstance(label, list):  \n",
    "                label_tensor = torch.zeros(len(self.label_to_idx), dtype=torch.float32)\n",
    "                for lbl in label:\n",
    "                    label_tensor[self.label_to_idx[lbl]] = 1.0\n",
    "            else:  \n",
    "                label_tensor = torch.tensor(self.label_to_idx[label], dtype=torch.long)\n",
    "        else:\n",
    "            label_tensor = torch.tensor(label, dtype=torch.long)  \n",
    "    \n",
    "        return image, label_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70927276-2a44-428c-a7c7-24430b4736e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "num_cpus = os.cpu_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae62168c-4ec8-4097-8189-5dd2f5f340b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = load_dataset(\"blanchon/EuroSAT_RGB\", split=\"train\")\n",
    "\n",
    "split_dataset_1 = dataset_1.train_test_split(test_size=0.6, seed=42)\n",
    "\n",
    "\n",
    "euroSAT_train = split_dataset_1['train'] \n",
    "euroSAT_test = split_dataset_1['test']    \n",
    "\n",
    "euroSAT_train = HFDatasetWrapper(euroSAT_train, transform=train_transform)\n",
    "euroSAT_test = HFDatasetWrapper(euroSAT_test, transform=test_transform)\n",
    "\n",
    "euroSAT_train_loader = DataLoader(euroSAT_train, batch_size=64, shuffle=True, num_workers = num_cpus // 2,persistent_workers=True,pin_memory=True)\n",
    "euroSAT_test_loader = DataLoader(euroSAT_test, batch_size=64, shuffle=False,num_workers = num_cpus // 2,persistent_workers=True,pin_memory=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e29d937-569d-480c-a074-515308417906",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2 = load_dataset(\"blanchon/PatternNet\", split=\"train\")\n",
    "split_dataset_2 = dataset_2.train_test_split(test_size=0.6, seed=42)\n",
    "\n",
    "patternNet_train = split_dataset_2['train']\n",
    "patternNet_test = split_dataset_2['test']\n",
    "\n",
    "patternNet_train = HFDatasetWrapper(patternNet_train, transform=train_transform)\n",
    "patternNet_test = HFDatasetWrapper(patternNet_test, transform=test_transform)\n",
    "\n",
    "patternNet_train_loader = DataLoader(patternNet_train, batch_size=64, shuffle=True, num_workers = num_cpus // 2,persistent_workers=True,pin_memory=True)\n",
    "patternNet_test_loader = DataLoader(patternNet_test, batch_size=64, shuffle=False, num_workers = num_cpus // 2,persistent_workers=True,pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0bf088b-18c5-454e-a10c-0a3d720fd7b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset_3 = load_dataset(\"blanchon/RESISC45\", split=\"train\")\n",
    "\n",
    "# split_dataset_3 = dataset_3.train_test_split(test_size=0.4, seed=42)\n",
    "\n",
    "\n",
    "# RESISC_train = split_dataset_3['train']8\n",
    "# RESISC_test = split_dataset_3['test']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f708922-65e3-4d55-a02d-34136de4d663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip /home/23ucs712/MLRSNet-master.zip -d /home/23ucs712/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30cbc155-b423-4031-bb43-cc6594f24cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 111666\n",
      "Classes: 46\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "data_dir = \"/home/23ucs712/MLRSNet-master/Images\"\n",
    "\n",
    "\n",
    "\n",
    "dataset = ImageFolder(root=data_dir, transform=test_transform)\n",
    "print(\"Total samples:\", len(dataset))\n",
    "print(\"Classes:\", len(dataset.classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d2ae208-0f9e-42e7-9d6c-25f4c454679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.6 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "MLRS_train_loader = DataLoader(train_dataset, batch_size=64,num_workers=num_cpus//2,shuffle=True)\n",
    "MLRS_test_loader = DataLoader(test_dataset, batch_size=64,num_workers=num_cpus//2,shuffle=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8632478-ecc3-4ab2-97f3-5c1e3a285d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install librosa soundfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c6e80e9-1ae6-45ee-843a-2690d7e098b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_num_classes = {\n",
    "    'EuroSAT': 10,\n",
    "    'PatternNet': 38,\n",
    "#    'RESISC45': 45,\n",
    "    'MLRS': 46,\n",
    "    'Advance': 13\n",
    "\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f5355c-08cb-41f2-a90a-cc52859e27a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_5 = load_dataset(\"blanchon/ADVANCE\", split='train')\n",
    "split_dataset_5 = dataset_5.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "advance_train = split_dataset_5['train']\n",
    "advance_test = split_dataset_5['test']\n",
    "\n",
    "all_labels = set(example['label'] for example in advance_train)\n",
    "sorted_labels = sorted(list(all_labels))\n",
    "label_to_idx = {label: idx for idx, label in enumerate(sorted_labels)} \n",
    "\n",
    "wrapped_advance_train = HFDatasetWrapper(\n",
    "    advance_train,\n",
    "    transform=train_transform,\n",
    "    label_key='label',\n",
    "    label_to_idx=label_to_idx\n",
    ")\n",
    "\n",
    "wrapped_advance_test = HFDatasetWrapper(\n",
    "    advance_test,\n",
    "    transform=test_transform,\n",
    "    label_key='label',\n",
    "    label_to_idx=label_to_idx\n",
    ")\n",
    "\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "labels = [label_to_idx[example['label']] for example in advance_train]\n",
    "class_sample_counts = [labels.count(i) for i in range(len(sorted_labels))]\n",
    "weights = [1.0 / class_sample_counts[label] for label in labels]\n",
    "\n",
    "sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "advance_train_loader = DataLoader(\n",
    "    wrapped_advance_train,\n",
    "    batch_size=64,\n",
    "    sampler=sampler,\n",
    "    num_workers=num_cpus // 2,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "advance_test_loader = DataLoader(\n",
    "    wrapped_advance_test,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=num_cpus // 2,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a6799b1-14c7-4f17-9eea-8cc6ee48e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "base = resnet50(weights='IMAGENET1K_V1')\n",
    "\n",
    "domain_list = ['EuroSAT','PatternNet','MLRS','Advance']\n",
    "model = ResNetWithAdapters(base,domain_list,domain_num_classes)\n",
    "\n",
    "# Freeze ResNet backbone\n",
    "for param in model.stem.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for layer in model.base_layers.values():\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "for param in model.avgpool.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d675fd5-119d-46dd-a588-1ffe7a271b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loaders = {\n",
    "    'EuroSAT': euroSAT_train_loader,\n",
    "    'PatternNet': patternNet_train_loader,\n",
    "#    'RESISC45': RESISC_train,\n",
    "    'MLRS': MLRS_train_loader,\n",
    "    'Advance': advance_train_loader\n",
    "}\n",
    "\n",
    "test_loaders = {\n",
    "    'EuroSAT': euroSAT_test_loader,\n",
    "    'PatternNet': patternNet_test_loader,\n",
    "#    'RESISC45': RESISC_test,\n",
    "    'MLRS': MLRS_test_loader,\n",
    "    'Advance': advance_test_loader\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9c788ab-80c7-4dde-b85a-fd5808a83b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loaders, domain_num_classes):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        print(f\"\\nEvaluating on domain: {domain}\")\n",
    "        progress_bar = tqdm(test_loaders[domain], desc=f\"{domain} Eval\", leave=False)\n",
    "\n",
    "        for images, labels in progress_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images, domain)\n",
    "\n",
    "            # Optional safety check\n",
    "            if outputs.shape[1] != domain_num_classes[domain]:\n",
    "                print(f\"[WARNING] Output dim {outputs.shape[1]} does not match expected {domain_num_classes[domain]} for {domain}\")\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            progress_bar.set_postfix(acc=f\"{100 * correct / total:.2f}%\")\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Final Accuracy on {domain}: {accuracy:.2f}%\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e834eeb-e78f-4851-9544-5a72e1f491f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_domain(model, current_domain):\n",
    "    for name, param in model.named_parameters():\n",
    "        if f\".{current_domain}.\" in name and (\"adapter\" in name or \"classifier\" in name):\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7f7c319-4aaf-4f97-b104-1b84cba73019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_parameters(model,domain):\n",
    "    return list(model.adapters[domain].parameters()) + list(model.classifiers[domain].parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e420fee-c35f-4b58-9872-6499b8714017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters:     28,645,547\n",
      "Trainable parameters: 1,250,058\n",
      "Frozen parameters:    27,395,489\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    frozen = total - trainable\n",
    "\n",
    "    print(f\"Total parameters:     {total:,}\")\n",
    "    print(f\"Trainable parameters: {trainable:,}\")\n",
    "    print(f\"Frozen parameters:    {frozen:,}\")\n",
    "count_parameters(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e544aa8-ccf6-4151-a993-e8ba384f4f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/20]\n",
      "\n",
      "Training on domain: EuroSAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EuroSAT]:   0%|                                                                                | 0/102 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 65124, 65125, 65126, 65127, 65128, 65129, 65130, 65131, 65132, 65133, 65134, 65135, 65136, 65137, 65138, 65139, 65140, 65141, 65143, 65144, 65145, 65146, 65147, 65148, 65149, 65151, 65152, 65153, 65154, 65155, 65156, 65157, 65158, 65159, 65160, 65161, 65162, 65163, 65164, 65165) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1251\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1251\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_empty\u001b[38;5;241m.\u001b[39mwait(remaining)\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdomain\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     33\u001b[0m freeze_domain(model, domain)\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n\u001b[1;32m     36\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     37\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:488\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iterator()\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 488\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1230\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._reset\u001b[0;34m(self, loader, first_iter)\u001b[0m\n\u001b[1;32m   1228\u001b[0m resume_iteration_cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_workers\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m resume_iteration_cnt \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1230\u001b[0m     return_idx, return_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_idx, _utils\u001b[38;5;241m.\u001b[39mworker\u001b[38;5;241m.\u001b[39m_ResumeIteration):\n\u001b[1;32m   1232\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m return_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1410\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1409\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1410\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1411\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1412\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1264\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1263\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1265\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1266\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 65124, 65125, 65126, 65127, 65128, 65129, 65130, 65131, 65132, 65133, 65134, 65135, 65136, 65137, 65138, 65139, 65140, 65141, 65143, 65144, 65145, 65146, 65147, 65148, 65149, 65151, 65152, 65153, 65154, 65155, 65156, 65157, 65158, 65159, 65160, 65161, 65162, 65163, 65164, 65165) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "optimizer = {}\n",
    "scheduler = {}\n",
    "\n",
    "for domain in domain_list:\n",
    "    optimizer[domain] = optim.Adam(domain_parameters(model, domain), lr=1e-3)\n",
    "    scheduler[domain] = StepLR(optimizer[domain], step_size=15, gamma=0.1)\n",
    "    \n",
    "num_epochs = 20\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    print(f\"\\nEpoch [{epoch+1}/{num_epochs}]\")\n",
    "\n",
    "    for domain, loader in train_loaders.items():\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        print(f\"\\nTraining on domain: {domain}\")\n",
    "        domain_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        progress_bar = tqdm(loader, desc=f\"[{domain}]\", leave=True)\n",
    "\n",
    "        freeze_domain(model, domain)\n",
    "\n",
    "        for images, labels in progress_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer[domain].zero_grad()\n",
    "            outputs = model(images, domain)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer[domain].step()\n",
    "\n",
    "            batch_size = images.size(0)\n",
    "            domain_loss += loss.item() * batch_size\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100 * correct / total:.2f}%' \n",
    "            })\n",
    "\n",
    "        avg_domain_loss = domain_loss / len(loader.dataset)\n",
    "        avg_domain_acc = 100 * correct / total\n",
    "        print(f\"Domain: {domain}, Epoch Loss: {avg_domain_loss:.4f}, Accuracy: {avg_domain_acc:.2f}%\")\n",
    "\n",
    "        scheduler[domain].step()\n",
    "\n",
    "        evaluate(model, test_loaders, domain_num_classes)\n",
    "\n",
    "    avg_total_loss = total_loss / total_samples\n",
    "    print(f\"\\nEpoch [{epoch+1}/{num_epochs}] Avg Total Loss: {avg_total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2c30b8-20ce-4bb4-a5ea-f57614eab1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
